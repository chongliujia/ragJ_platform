# Phase II (v0.2.0) Milestone: Core RAG Pipeline Implementation

**Objective:** To implement the end-to-end RAG (Retrieval-Augmented Generation) pipeline. This phase will enable the platform to ingest documents, index them into a vector store, and perform question-answering based on the indexed knowledge.

---

## 1. Key Deliverables

- **Knowledge Base Management**: APIs to create, list, and manage knowledge bases (mapped to Milvus collections).
- **Document Processing Pipeline**: An asynchronous pipeline to handle document uploads, text extraction, chunking, embedding, and indexing into Milvus.
- **RAG Chat API**: An endpoint that takes a user query, retrieves relevant context from the knowledge base, and generates an answer using the LLM.
- **Updated `requirements.txt`**: Freeze the new dependencies for this phase.

---

## 2. Detailed Task Breakdown

### Task 2.1: Knowledge Base Service & API

- **Description**: Implement the logic to manage knowledge bases. Each knowledge base will correspond to a collection in Milvus.
- **Sub-tasks**:
    - [ ] **`MilvusService`**: Create a service to handle all interactions with Milvus (e.g., creating collections, checking existence, inserting vectors, searching).
    - [ ] **Data Schema**: Define the Pydantic schema for a `KnowledgeBase` resource.
    - [ ] **API Endpoints**: Implement `POST /api/v1/knowledge_bases/` and `GET /api/v1/knowledge_bases/` endpoints.
- **Acceptance Criteria**:
    - Able to create a new knowledge base via the API, which results in a new collection being created in Milvus.
    - Able to list all existing knowledge bases.

### Task 2.2: Document Processing and Indexing Pipeline

- **Description**: Develop the pipeline for processing uploaded documents.
- **Sub-tasks**:
    - [ ] **File Handling**: Implement API endpoint for file uploads (`POST /api/v1/knowledge_bases/{kb_id}/documents/`).
    - [ ] **Text Extraction**: Add support for parsing text from `.txt` and `.md` files. (Support for `.pdf` can be a future task).
    - [ ] **Text Splitting**: Implement a text chunking strategy (e.g., recursive character text splitter).
    - [ ] **Embedding**: Use the `Qwen` embedding model via `LLMService` to generate embeddings for each text chunk.
    - [ ] **Indexing**: Insert the text chunks and their corresponding embeddings into the correct Milvus collection.
- **Acceptance Criteria**:
    - Able to upload a `.txt` file to a specific knowledge base.
    - The system successfully processes the file, and the text chunks and vectors are stored in Milvus.

### Task 2.3: Core RAG Chat API

- **Description**: Implement the main chat endpoint that utilizes the RAG pipeline.
- **Sub-tasks**:
    - [ ] **Query Embedding**: When a query is received, generate its embedding using the `Qwen` model.
    - [ ] **Vector Search**: Search the relevant Milvus collection for the most similar vectors.
    - [ ] **Prompt Engineering**: Create a prompt that includes the original query and the retrieved context.
    - [ ] **LLM Generation**: Send the engineered prompt to the `Qwen` chat model to get the final answer.
    - [ ] **API Endpoint**: Implement the `POST /api/v1/chat/` endpoint.
- **Acceptance Criteria**:
    - The chat API responds to a query with an answer generated based on the content of the documents in the knowledge base.

### Task 2.4: Project Cleanup and Refinement

- **Description**: Update dependencies and documentation.
- **Sub-tasks**:
    - [ ] **Dependencies**: Re-introduce `langchain` and `langgraph` and resolve any version conflicts. Update `requirements.txt`.
    - [ ] **README**: Update the main `README.md` to reflect the new features and how to use them.
- **Acceptance Criteria**:
    - The project runs without dependency errors.
    - The documentation is up-to-date.

---

## 3. Timeline

- **Estimated Duration**: 2-3 weeks.
- **Target Completion Date**: TBD. 
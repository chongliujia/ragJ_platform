"""
LangGraphå·¥ä½œæµå¯è§†åŒ–
ç”ŸæˆRAGå·¥ä½œæµçš„å›¾è¡¨å’Œè¯´æ˜
"""

import os
from datetime import datetime


def generate_workflow_visualization():
    """ç”Ÿæˆå·¥ä½œæµå¯è§†åŒ–æ–‡æ¡£"""
    
    mermaid_diagram = """
```mermaid
graph TD
    A[å¼€å§‹] --> B[analyze_query<br/>åˆ†ææŸ¥è¯¢]
    B --> C[generate_embedding<br/>ç”Ÿæˆå‘é‡åµŒå…¥]
    C --> D{embedding_generated?<br/>å‘é‡ç”ŸæˆæˆåŠŸ?}
    
    D -->|Yes| E[retrieve_documents<br/>æ£€ç´¢æ–‡æ¡£]
    D -->|No| F[fallback_response<br/>å¤‡ç”¨å›ç­”]
    
    E --> G{docs_retrieved?<br/>æ£€ç´¢åˆ°æ–‡æ¡£?}
    G -->|Yes| H[rerank_documents<br/>é‡æ–°æ’åº]
    G -->|No| F
    
    H --> I[generate_response<br/>ç”Ÿæˆå›ç­”]
    I --> J[ç»“æŸ]
    F --> J
    
    style A fill:#e1f5fe
    style J fill:#e8f5e8
    style D fill:#fff3e0
    style G fill:#fff3e0
    style F fill:#ffebee
    style I fill:#e8f5e8
```
"""
    
    workflow_steps = {
        "analyze_query": {
            "name": "åˆ†ææŸ¥è¯¢",
            "description": "åˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ„å›¾ã€å¤æ‚åº¦å’Œè¯­è¨€",
            "inputs": ["ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬"],
            "outputs": ["æŸ¥è¯¢åˆ†æç»“æœ"],
            "logic": "æ£€æµ‹æŸ¥è¯¢è¯­è¨€(ä¸­æ–‡/è‹±æ–‡)ï¼Œåˆ¤æ–­æŸ¥è¯¢ç±»å‹å’Œå¤æ‚åº¦"
        },
        "generate_embedding": {
            "name": "ç”Ÿæˆå‘é‡åµŒå…¥",
            "description": "å°†ç”¨æˆ·æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º",
            "inputs": ["æŸ¥è¯¢æ–‡æœ¬"],
            "outputs": ["æŸ¥è¯¢å‘é‡", "ç”ŸæˆçŠ¶æ€"],
            "logic": "è°ƒç”¨åµŒå…¥æ¨¡å‹APIï¼Œå¤„ç†å¤±è´¥æƒ…å†µ"
        },
        "retrieve_documents": {
            "name": "æ£€ç´¢æ–‡æ¡£", 
            "description": "ä½¿ç”¨æ··åˆæœç´¢æ£€ç´¢ç›¸å…³æ–‡æ¡£",
            "inputs": ["æŸ¥è¯¢å‘é‡", "æŸ¥è¯¢æ–‡æœ¬", "çŸ¥è¯†åº“ID"],
            "outputs": ["æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨"],
            "logic": "å¹¶è¡Œæ‰§è¡Œå‘é‡æœç´¢å’Œå…³é”®è¯æœç´¢ï¼Œåˆå¹¶ç»“æœ"
        },
        "rerank_documents": {
            "name": "é‡æ–°æ’åº",
            "description": "å¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œç›¸å…³æ€§é‡æ–°æ’åº",
            "inputs": ["æ–‡æ¡£åˆ—è¡¨", "æŸ¥è¯¢æ–‡æœ¬"],
            "outputs": ["é‡æ–°æ’åºçš„æ–‡æ¡£", "ä¸Šä¸‹æ–‡æ–‡æœ¬"],
            "logic": "ä½¿ç”¨é‡æ’åºæ¨¡å‹æé«˜æ£€ç´¢ç²¾åº¦"
        },
        "generate_response": {
            "name": "ç”Ÿæˆå›ç­”",
            "description": "åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆå›ç­”",
            "inputs": ["ä¸Šä¸‹æ–‡æ–‡æœ¬", "æŸ¥è¯¢æ–‡æœ¬"],
            "outputs": ["AIå›ç­”", "ä½¿ç”¨ç»Ÿè®¡"],
            "logic": "æ„é€ RAGæç¤ºè¯ï¼Œè°ƒç”¨LLMç”Ÿæˆå›ç­”ï¼Œæ·»åŠ å¼•ç”¨ä¿¡æ¯"
        },
        "fallback_response": {
            "name": "å¤‡ç”¨å›ç­”",
            "description": "å½“RAGæµç¨‹å¤±è´¥æ—¶æä¾›å¤‡ç”¨å›ç­”",
            "inputs": ["æŸ¥è¯¢æ–‡æœ¬"],
            "outputs": ["å¤‡ç”¨å›ç­”"],
            "logic": "ç›´æ¥è°ƒç”¨LLMè¿›è¡Œæ ‡å‡†å¯¹è¯ï¼Œä¸ä½¿ç”¨çŸ¥è¯†åº“"
        }
    }
    
    decision_points = {
        "should_retrieve": {
            "condition": "embedding_generated",
            "description": "æ£€æŸ¥å‘é‡åµŒå…¥æ˜¯å¦ç”ŸæˆæˆåŠŸ",
            "paths": {
                "retrieve": "å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»§ç»­æ–‡æ¡£æ£€ç´¢",
                "fallback": "å‘é‡ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å›ç­”"
            }
        },
        "should_rerank": {
            "condition": "docs_retrieved > 0",
            "description": "æ£€æŸ¥æ˜¯å¦æ£€ç´¢åˆ°æ–‡æ¡£",
            "paths": {
                "rerank": "æ£€ç´¢åˆ°æ–‡æ¡£ï¼Œè¿›è¡Œé‡æ–°æ’åº",
                "fallback": "æœªæ£€ç´¢åˆ°æ–‡æ¡£ï¼Œä½¿ç”¨å¤‡ç”¨å›ç­”"
            }
        }
    }
    
    # ç”Ÿæˆè¯¦ç»†è¯´æ˜
    documentation = f"""
# LangGraph RAG å·¥ä½œæµå¯è§†åŒ–

## å·¥ä½œæµå›¾è¡¨

{mermaid_diagram}

## èŠ‚ç‚¹è¯¦ç»†è¯´æ˜

"""
    
    for step_id, step_info in workflow_steps.items():
        documentation += f"""
### {step_info['name']} ({step_id})

**æè¿°**: {step_info['description']}

**è¾“å…¥**: {', '.join(step_info['inputs'])}

**è¾“å‡º**: {', '.join(step_info['outputs'])}

**å¤„ç†é€»è¾‘**: {step_info['logic']}

---
"""
    
    documentation += """
## å†³ç­–ç‚¹è¯´æ˜

"""
    
    for decision_id, decision_info in decision_points.items():
        documentation += f"""
### {decision_id}

**æ¡ä»¶**: {decision_info['condition']}

**æè¿°**: {decision_info['description']}

**è·¯å¾„é€‰æ‹©**:
"""
        for path, desc in decision_info['paths'].items():
            documentation += f"- **{path}**: {desc}\n"
        documentation += "\n---\n"
    
    documentation += f"""
## å·¥ä½œæµç‰¹æ€§

### ğŸ”„ çŠ¶æ€ç®¡ç†
- **è‡ªåŠ¨çŠ¶æ€è·Ÿè¸ª**: æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡ŒçŠ¶æ€å’Œç»“æœè‡ªåŠ¨ä¿å­˜
- **çŠ¶æ€ä¼ é€’**: çŠ¶æ€åœ¨å„èŠ‚ç‚¹é—´æ— ç¼ä¼ é€’
- **é”™è¯¯çŠ¶æ€**: è®°å½•é”™è¯¯ä¿¡æ¯å’Œæ¢å¤çŠ¶æ€

### ğŸŒŠ æµç¨‹æ§åˆ¶
- **æ¡ä»¶åˆ†æ”¯**: åŸºäºæ‰§è¡Œç»“æœè‡ªåŠ¨é€‰æ‹©ä¸‹ä¸€æ­¥
- **é”™è¯¯å¤„ç†**: ä¼˜é›…çš„é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶
- **å¹¶è¡Œå¤„ç†**: å‘é‡æœç´¢å’Œå…³é”®è¯æœç´¢å¹¶è¡Œæ‰§è¡Œ

### ğŸ“Š å¯è§‚å¯Ÿæ€§
- **æ‰§è¡Œæ—¥å¿—**: è¯¦ç»†çš„æ­¥éª¤æ‰§è¡Œæ—¥å¿—
- **æ€§èƒ½ç›‘æ§**: æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
- **é”™è¯¯è¯Šæ–­**: è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª

### ğŸ›¡ï¸ å®¹é”™æœºåˆ¶
- **å¤šçº§å›é€€**: å‘é‡åŒ–å¤±è´¥ â†’ æ£€ç´¢å¤±è´¥ â†’ ç”Ÿæˆå¤±è´¥çš„å¤šå±‚å›é€€
- **éƒ¨åˆ†æˆåŠŸ**: å³ä½¿æŸäº›æ­¥éª¤å¤±è´¥ä¹Ÿèƒ½æä¾›æœ‰ç”¨çš„å›ç­”
- **æœåŠ¡é™çº§**: Elasticsearchä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨çº¯å‘é‡æœç´¢

## æ‰©å±•èƒ½åŠ›

### æ·»åŠ æ–°èŠ‚ç‚¹
```python
async def new_processing_step(state: ChatState) -> ChatState:
    # æ–°çš„å¤„ç†é€»è¾‘
    state["new_data"] = "processed"
    return state

workflow.add_node("new_step", new_processing_step)
```

### è‡ªå®šä¹‰å†³ç­–é€»è¾‘
```python
def custom_condition(state: ChatState) -> str:
    if state["custom_metric"] > threshold:
        return "path_a"
    return "path_b"

workflow.add_conditional_edges(
    "source_node",
    custom_condition,
    {{"path_a": "node_a", "path_b": "node_b"}}
)
```

### æ€§èƒ½ä¼˜åŒ–
- **ç¼“å­˜ç­–ç•¥**: æŸ¥è¯¢å‘é‡å’Œæ£€ç´¢ç»“æœç¼“å­˜
- **æ‰¹å¤„ç†**: å¤šä¸ªæŸ¥è¯¢çš„æ‰¹é‡å¤„ç†
- **å¼‚æ­¥ä¼˜åŒ–**: æœ€å¤§åŒ–å¹¶å‘å¤„ç†èƒ½åŠ›

## ä½¿ç”¨åœºæ™¯

1. **ä¼ä¸šçŸ¥è¯†åº“é—®ç­”**: åŸºäºä¼ä¸šæ–‡æ¡£çš„æ™ºèƒ½é—®ç­”
2. **å®¢æˆ·æœåŠ¡**: è‡ªåŠ¨åŒ–å®¢æˆ·æŸ¥è¯¢å¤„ç†
3. **æ•™è‚²è¾…åŠ©**: åŸºäºæ•™æçš„å­¦ä¹ è¾…å¯¼
4. **ç ”ç©¶åŠ©æ‰‹**: ç§‘ç ”æ–‡çŒ®æ£€ç´¢å’Œåˆ†æ
5. **æ³•å¾‹å’¨è¯¢**: æ³•å¾‹æ–‡æ¡£æŸ¥è¯¢å’Œè§£é‡Š
6. **åŒ»ç–—é—®ç­”**: åŒ»å­¦çŸ¥è¯†åº“æŸ¥è¯¢
7. **æŠ€æœ¯æ”¯æŒ**: äº§å“æ–‡æ¡£å’Œæ•…éšœæ’é™¤
8. **å†…å®¹åˆ›ä½œ**: åŸºäºèµ„æ–™çš„å†…å®¹ç”Ÿæˆ

## ç›‘æ§æŒ‡æ ‡

- **å“åº”æ—¶é—´**: ç«¯åˆ°ç«¯å“åº”æ—¶é—´å’Œå„æ­¥éª¤è€—æ—¶
- **æ£€ç´¢å‡†ç¡®ç‡**: æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§è¯„åˆ†
- **ç”¨æˆ·æ»¡æ„åº¦**: åŸºäºç”¨æˆ·åé¦ˆçš„è´¨é‡è¯„ä¼°
- **ç³»ç»Ÿèµ„æº**: CPUã€å†…å­˜ã€ç½‘ç»œä½¿ç”¨æƒ…å†µ
- **é”™è¯¯ç‡**: å„ç±»é”™è¯¯çš„å‘ç”Ÿé¢‘ç‡å’Œå¤„ç†æˆåŠŸç‡

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    return documentation


def save_visualization_docs():
    """ä¿å­˜å¯è§†åŒ–æ–‡æ¡£"""
    docs_dir = "docs"
    if not os.path.exists(docs_dir):
        os.makedirs(docs_dir)
    
    doc_content = generate_workflow_visualization()
    
    with open(os.path.join(docs_dir, "langgraph_workflow_visualization.md"), "w", encoding="utf-8") as f:
        f.write(doc_content)
    
    print("âœ… LangGraphå·¥ä½œæµå¯è§†åŒ–æ–‡æ¡£å·²ç”Ÿæˆ")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: {os.path.join(docs_dir, 'langgraph_workflow_visualization.md')}")


if __name__ == "__main__":
    save_visualization_docs()
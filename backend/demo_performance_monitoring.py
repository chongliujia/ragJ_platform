"""
å·¥ä½œæµæ€§èƒ½ç›‘æ§æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„æ€§èƒ½ç›‘æ§åŠŸèƒ½åŒ…æ‹¬æŒ‡æ ‡æ”¶é›†ã€å‘Šè­¦ã€åˆ†æç­‰
"""

import asyncio
import time
import json
from datetime import datetime
from typing import Dict, Any

from app.schemas.workflow import (
    WorkflowDefinition,
    WorkflowNode,
    WorkflowEdge,
    NodeFunctionSignature,
    NodeInputSchema,
    NodeOutputSchema,
    DataType
)
from app.services.workflow_execution_engine import workflow_execution_engine
from app.services.workflow_performance_monitor import (
    workflow_performance_monitor,
    AlertRule,
    AlertSeverity,
    PerformanceMetric,
    MetricType
)


def create_monitoring_demo_workflow() -> WorkflowDefinition:
    """åˆ›å»ºç”¨äºç›‘æ§æ¼”ç¤ºçš„å·¥ä½œæµ"""
    
    nodes = [
        WorkflowNode(
            id="input_node",
            type="input",
            name="è¾“å…¥èŠ‚ç‚¹",
            description="æ¥æ”¶ç”¨æˆ·è¾“å…¥",
            function_signature=NodeFunctionSignature(
                name="input_data",
                description="è¾“å…¥æ•°æ®",
                category="io",
                inputs=[],
                outputs=[
                    NodeOutputSchema(
                        name="data",
                        type=DataType.OBJECT,
                        description="è¾“å…¥æ•°æ®",
                        required=True
                    )
                ]
            ),
            position={"x": 100, "y": 100}
        ),
        WorkflowNode(
            id="slow_node",
            type="llm",
            name="æ…¢é€ŸLLMèŠ‚ç‚¹",
            description="æ¨¡æ‹Ÿæ…¢é€Ÿæ‰§è¡Œçš„LLMèŠ‚ç‚¹",
            function_signature=NodeFunctionSignature(
                name="slow_llm",
                description="æ…¢é€ŸLLMå¤„ç†",
                category="llm",
                inputs=[
                    NodeInputSchema(
                        name="prompt",
                        type=DataType.STRING,
                        description="æç¤º",
                        required=True
                    )
                ],
                outputs=[
                    NodeOutputSchema(
                        name="content",
                        type=DataType.STRING,
                        description="ç”Ÿæˆå†…å®¹",
                        required=True
                    )
                ]
            ),
            config={
                "model": "qwen-turbo",
                "temperature": 0.7,
                "simulate_slow": True,
                "min_delay": 2.0,
                "max_delay": 5.0
            },
            position={"x": 400, "y": 100}
        ),
        WorkflowNode(
            id="error_prone_node",
            type="classifier",
            name="æ˜“é”™åˆ†ç±»èŠ‚ç‚¹",
            description="æ¨¡æ‹Ÿå®¹æ˜“å‡ºé”™çš„åˆ†ç±»èŠ‚ç‚¹",
            function_signature=NodeFunctionSignature(
                name="error_prone_classifier",
                description="å®¹æ˜“å‡ºé”™çš„åˆ†ç±»å™¨",
                category="ai",
                inputs=[
                    NodeInputSchema(
                        name="text",
                        type=DataType.STRING,
                        description="å¾…åˆ†ç±»æ–‡æœ¬",
                        required=True
                    )
                ],
                outputs=[
                    NodeOutputSchema(
                        name="class",
                        type=DataType.STRING,
                        description="åˆ†ç±»ç»“æœ",
                        required=True
                    )
                ]
            ),
            config={
                "classes": ["æ­£é¢", "è´Ÿé¢", "ä¸­æ€§"],
                "error_rate": 0.3,  # 30%çš„é”™è¯¯ç‡
                "simulate_errors": True
            },
            position={"x": 700, "y": 100}
        ),
        WorkflowNode(
            id="output_node",
            type="output",
            name="è¾“å‡ºèŠ‚ç‚¹",
            description="è¾“å‡ºæœ€ç»ˆç»“æœ",
            function_signature=NodeFunctionSignature(
                name="output_data",
                description="è¾“å‡ºæ•°æ®",
                category="io",
                inputs=[
                    NodeInputSchema(
                        name="data",
                        type=DataType.OBJECT,
                        description="è¾“å‡ºæ•°æ®",
                        required=True
                    )
                ],
                outputs=[
                    NodeOutputSchema(
                        name="result",
                        type=DataType.OBJECT,
                        description="æœ€ç»ˆç»“æœ",
                        required=True
                    )
                ]
            ),
            position={"x": 1000, "y": 100}
        )
    ]
    
    edges = [
        WorkflowEdge(
            id="edge_1",
            source="input_node",
            target="slow_node",
            source_output="data",
            target_input="prompt",
            transform="value.get('text', 'default prompt')"
        ),
        WorkflowEdge(
            id="edge_2",
            source="slow_node",
            target="error_prone_node",
            source_output="content",
            target_input="text"
        ),
        WorkflowEdge(
            id="edge_3",
            source="error_prone_node",
            target="output_node",
            source_output="class",
            target_input="data"
        )
    ]
    
    return WorkflowDefinition(
        id="monitoring_demo_workflow",
        name="æ€§èƒ½ç›‘æ§æ¼”ç¤ºå·¥ä½œæµ",
        description="ç”¨äºæ¼”ç¤ºæ€§èƒ½ç›‘æ§åŠŸèƒ½çš„å·¥ä½œæµ",
        version="1.0.0",
        nodes=nodes,
        edges=edges,
        global_config={
            "timeout": 30,
            "enable_monitoring": True,
            "enable_alerts": True
        }
    )


async def setup_performance_monitoring():
    """è®¾ç½®æ€§èƒ½ç›‘æ§"""
    
    print("ğŸ”§ é…ç½®æ€§èƒ½ç›‘æ§ç³»ç»Ÿ")
    print("=" * 50)
    
    # å¯åŠ¨æ€§èƒ½ç›‘æ§
    await workflow_execution_engine.start_performance_monitoring()
    
    # æ·»åŠ è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™
    custom_rules = [
        AlertRule(
            name="workflow_execution_very_slow",
            metric_name="workflow_execution_duration",
            threshold=10.0,  # 10ç§’
            comparison=">",
            severity=AlertSeverity.ERROR,
            message_template="å·¥ä½œæµæ‰§è¡Œæ—¶é—´è¿‡é•¿: {current_value:.2f}ç§’ (é˜ˆå€¼: {threshold}ç§’)",
            labels={"workflow_id": "monitoring_demo_workflow"}
        ),
        AlertRule(
            name="node_error_rate_critical",
            metric_name="node_error_rate",
            threshold=0.5,  # 50%
            comparison=">",
            severity=AlertSeverity.CRITICAL,
            message_template="èŠ‚ç‚¹é”™è¯¯ç‡è¾¾åˆ°ä¸´ç•Œå€¼: {current_value:.2%} (é˜ˆå€¼: {threshold:.2%})",
            labels={"node_id": "error_prone_node"}
        ),
        AlertRule(
            name="node_execution_slow",
            metric_name="node_execution_duration",
            threshold=3.0,  # 3ç§’
            comparison=">",
            severity=AlertSeverity.WARNING,
            message_template="èŠ‚ç‚¹æ‰§è¡Œç¼“æ…¢: {current_value:.2f}ç§’ (é˜ˆå€¼: {threshold}ç§’)"
        )
    ]\n    \n    # æ·»åŠ å‘Šè­¦è§„åˆ™\n    for rule in custom_rules:\n        workflow_performance_monitor.add_alert_rule(rule)\n        print(f\"âœ… æ·»åŠ å‘Šè­¦è§„åˆ™: {rule.name}\")\n    \n    print(f\"ğŸ“Š æ€§èƒ½ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨\")\n    print(f\"ğŸš¨ å‘Šè­¦è§„åˆ™å·²é…ç½®: {len(custom_rules)}ä¸ª\")\n\n\nasync def run_monitoring_demo():\n    \"\"\"è¿è¡Œç›‘æ§æ¼”ç¤º\"\"\"\n    \n    print(\"\\nğŸš€ å¼€å§‹æ€§èƒ½ç›‘æ§æ¼”ç¤º\")\n    print(\"=\" * 50)\n    \n    # åˆ›å»ºå·¥ä½œæµ\n    workflow_def = create_monitoring_demo_workflow()\n    \n    # æ¨¡æ‹Ÿå¤šæ¬¡æ‰§è¡Œä»¥äº§ç”Ÿæ€§èƒ½æ•°æ®\n    execution_results = []\n    \n    for i in range(10):\n        print(f\"\\nğŸ”„ æ‰§è¡Œç¬¬ {i+1} æ¬¡å·¥ä½œæµ...\")\n        \n        # å‡†å¤‡è¾“å…¥æ•°æ®\n        input_data = {\n            \"text\": f\"è¿™æ˜¯ç¬¬{i+1}æ¬¡æµ‹è¯•ï¼Œå†…å®¹ä¼šå½±å“æ‰§è¡Œç»“æœ\",\n            \"execution_round\": i + 1,\n            \"timestamp\": datetime.now().isoformat()\n        }\n        \n        try:\n            # æ‰§è¡Œå·¥ä½œæµ\n            start_time = time.time()\n            context = await workflow_execution_engine.execute_workflow(\n                workflow_definition=workflow_def,\n                input_data=input_data,\n                debug=False\n            )\n            \n            execution_time = time.time() - start_time\n            execution_results.append({\n                \"round\": i + 1,\n                \"status\": context.status,\n                \"duration\": execution_time,\n                \"steps\": len(context.steps),\n                \"errors\": len([s for s in context.steps if s.status == \"error\"])\n            })\n            \n            print(f\"   âœ… çŠ¶æ€: {context.status}, è€—æ—¶: {execution_time:.2f}ç§’\")\n            \n        except Exception as e:\n            print(f\"   âŒ æ‰§è¡Œå¤±è´¥: {str(e)}\")\n            execution_results.append({\n                \"round\": i + 1,\n                \"status\": \"error\",\n                \"duration\": 0,\n                \"steps\": 0,\n                \"errors\": 1\n            })\n        \n        # çŸ­æš‚å»¶è¿Ÿ\n        await asyncio.sleep(1)\n    \n    return execution_results\n\n\nasync def analyze_performance_data():\n    \"\"\"åˆ†ææ€§èƒ½æ•°æ®\"\"\"\n    \n    print(\"\\nğŸ“Š æ€§èƒ½æ•°æ®åˆ†æ\")\n    print(\"=\" * 50)\n    \n    # è·å–æ€§èƒ½ä»ªè¡¨æ¿\n    dashboard = workflow_execution_engine.get_performance_dashboard()\n    \n    if not dashboard.get(\"performance_monitoring_enabled\", True):\n        print(\"âš ï¸  æ€§èƒ½ç›‘æ§æœªå¯ç”¨\")\n        return\n    \n    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡\n    stats = dashboard.get(\"statistics\", {})\n    \n    print(\"ğŸ“ˆ å·¥ä½œæµç»Ÿè®¡:\")\n    workflow_stats = stats.get(\"workflow_statistics\", {})\n    if workflow_stats:\n        print(f\"   æ€»æ‰§è¡Œæ¬¡æ•°: {workflow_stats.get('total_executions', 0)}\")\n        print(f\"   æˆåŠŸæ‰§è¡Œæ¬¡æ•°: {workflow_stats.get('completed_executions', 0)}\")\n        print(f\"   å¤±è´¥æ‰§è¡Œæ¬¡æ•°: {workflow_stats.get('failed_executions', 0)}\")\n        print(f\"   å¹³å‡æ‰§è¡Œæ—¶é—´: {workflow_stats.get('average_execution_time', 0):.2f}ç§’\")\n        print(f\"   å¤„ç†èŠ‚ç‚¹æ€»æ•°: {workflow_stats.get('total_nodes_processed', 0)}\")\n    \n    print(\"\\nğŸ”§ èŠ‚ç‚¹ç»Ÿè®¡:\")\n    node_stats = stats.get(\"node_statistics\", {})\n    if node_stats:\n        print(f\"   èŠ‚ç‚¹æ€»æ•°: {node_stats.get('total_nodes', 0)}\")\n        print(f\"   èŠ‚ç‚¹æ‰§è¡Œæ€»æ¬¡æ•°: {node_stats.get('total_executions', 0)}\")\n        print(f\"   å¹³å‡èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´: {node_stats.get('average_execution_time', 0):.2f}ç§’\")\n        \n        # æ˜¾ç¤ºæœ€æ…¢çš„èŠ‚ç‚¹\n        slowest_nodes = node_stats.get('slowest_nodes', [])\n        if slowest_nodes:\n            print(f\"   æœ€æ…¢çš„èŠ‚ç‚¹:\")\n            for node in slowest_nodes[:3]:\n                print(f\"     â€¢ {node['node_name']}: {node['average_duration']:.2f}ç§’\")\n        \n        # æ˜¾ç¤ºæœ€å®¹æ˜“å‡ºé”™çš„èŠ‚ç‚¹\n        error_prone_nodes = node_stats.get('most_error_prone_nodes', [])\n        if error_prone_nodes:\n            print(f\"   æœ€å®¹æ˜“å‡ºé”™çš„èŠ‚ç‚¹:\")\n            for node in error_prone_nodes[:3]:\n                print(f\"     â€¢ {node['node_name']}: {node['error_rate']:.2%}é”™è¯¯ç‡\")\n    \n    print(\"\\nğŸ–¥ï¸  ç³»ç»Ÿç»Ÿè®¡:\")\n    system_stats = stats.get(\"system_statistics\", {})\n    if system_stats:\n        print(f\"   å¹³å‡CPUä½¿ç”¨ç‡: {system_stats.get('average_cpu_usage', 0):.1f}%\")\n        print(f\"   å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {system_stats.get('average_memory_usage', 0):.1f}%\")\n        print(f\"   å½“å‰è¿›ç¨‹æ•°: {system_stats.get('current_process_count', 0)}\")\n        print(f\"   å½“å‰çº¿ç¨‹æ•°: {system_stats.get('current_thread_count', 0)}\")\n\n\nasync def demonstrate_alerts():\n    \"\"\"æ¼”ç¤ºå‘Šè­¦åŠŸèƒ½\"\"\"\n    \n    print(\"\\nğŸš¨ å‘Šè­¦ç³»ç»Ÿæ¼”ç¤º\")\n    print(\"=\" * 50)\n    \n    # è·å–å‘Šè­¦æ‘˜è¦\n    alert_summary = workflow_execution_engine.get_alert_summary()\n    \n    if not alert_summary.get(\"performance_monitoring_enabled\", True):\n        print(\"âš ï¸  æ€§èƒ½ç›‘æ§æœªå¯ç”¨\")\n        return\n    \n    # æ˜¾ç¤ºæ´»è·ƒå‘Šè­¦\n    active_alerts = alert_summary.get(\"active_alerts\", {})\n    total_alerts = active_alerts.get(\"total\", 0)\n    \n    print(f\"ğŸ“Š å‘Šè­¦ç»Ÿè®¡:\")\n    print(f\"   æ€»å‘Šè­¦æ•°: {total_alerts}\")\n    print(f\"   ä¸¥é‡å‘Šè­¦: {active_alerts.get('critical', 0)}\")\n    print(f\"   é”™è¯¯å‘Šè­¦: {active_alerts.get('error', 0)}\")\n    print(f\"   è­¦å‘Šå‘Šè­¦: {active_alerts.get('warning', 0)}\")\n    print(f\"   ä¿¡æ¯å‘Šè­¦: {active_alerts.get('info', 0)}\")\n    \n    # æ˜¾ç¤ºæœ€è¿‘çš„å‘Šè­¦\n    recent_alerts = alert_summary.get(\"recent_alerts\", [])\n    if recent_alerts:\n        print(f\"\\nğŸ”” æœ€è¿‘çš„å‘Šè­¦:\")\n        for alert in recent_alerts[-5:]:\n            severity_icon = {\n                \"critical\": \"ğŸ”´\",\n                \"error\": \"ğŸŸ \",\n                \"warning\": \"ğŸŸ¡\",\n                \"info\": \"ğŸ”µ\"\n            }.get(alert.get(\"severity\", \"info\"), \"ğŸ”µ\")\n            \n            print(f\"   {severity_icon} {alert.get('message', 'Unknown alert')}\")\n    \n    # æ˜¾ç¤ºå‘Šè­¦è§„åˆ™\n    alert_rules = alert_summary.get(\"alert_rules\", [])\n    if alert_rules:\n        print(f\"\\nğŸ“‹ å‘Šè­¦è§„åˆ™ ({len(alert_rules)}ä¸ª):\")\n        for rule in alert_rules:\n            print(f\"   â€¢ {rule['name']}: {rule['metric_name']} {rule['comparison']} {rule['threshold']}\")\n\n\nasync def demonstrate_detailed_reports():\n    \"\"\"æ¼”ç¤ºè¯¦ç»†æŠ¥å‘ŠåŠŸèƒ½\"\"\"\n    \n    print(\"\\nğŸ“‹ è¯¦ç»†æŠ¥å‘Šæ¼”ç¤º\")\n    print(\"=\" * 50)\n    \n    # è·å–å·¥ä½œæµæ€§èƒ½æŠ¥å‘Š\n    workflow_report = workflow_execution_engine.get_workflow_performance_report(\n        \"monitoring_demo_workflow\"\n    )\n    \n    if \"error\" not in workflow_report:\n        print(\"ğŸ“Š å·¥ä½œæµæ€§èƒ½æŠ¥å‘Š:\")\n        summary = workflow_report.get(\"summary\", {})\n        performance = workflow_report.get(\"performance\", {})\n        \n        print(f\"   æ€»æ‰§è¡Œæ¬¡æ•°: {summary.get('total_executions', 0)}\")\n        print(f\"   æˆåŠŸç‡: {summary.get('success_rate', 0):.2%}\")\n        print(f\"   å¹³å‡æ‰§è¡Œæ—¶é—´: {performance.get('average_duration', 0):.2f}ç§’\")\n        print(f\"   æœ€å¿«æ‰§è¡Œæ—¶é—´: {performance.get('min_duration', 0):.2f}ç§’\")\n        print(f\"   æœ€æ…¢æ‰§è¡Œæ—¶é—´: {performance.get('max_duration', 0):.2f}ç§’\")\n    \n    # è·å–èŠ‚ç‚¹æ€§èƒ½æŠ¥å‘Š\n    node_report = workflow_execution_engine.get_node_performance_report(\"slow_node\")\n    \n    if \"error\" not in node_report:\n        print(f\"\\nğŸ”§ èŠ‚ç‚¹æ€§èƒ½æŠ¥å‘Š (slow_node):\")\n        basic_info = node_report.get(\"basic_info\", {})\n        performance = node_report.get(\"performance\", {})\n        reliability = node_report.get(\"reliability\", {})\n        trend = node_report.get(\"trend_analysis\", {})\n        \n        print(f\"   èŠ‚ç‚¹åç§°: {basic_info.get('node_name', 'Unknown')}\")\n        print(f\"   æ‰§è¡Œæ¬¡æ•°: {basic_info.get('execution_count', 0)}\")\n        print(f\"   å¹³å‡æ‰§è¡Œæ—¶é—´: {performance.get('average_duration', 0):.2f}ç§’\")\n        print(f\"   æˆåŠŸç‡: {reliability.get('success_rate', 0):.2%}\")\n        print(f\"   é”™è¯¯ç‡: {reliability.get('error_rate', 0):.2%}\")\n        \n        if trend:\n            print(f\"   æ€§èƒ½è¶‹åŠ¿: {trend.get('trend_direction', 'unknown')}\")\n            print(f\"   è¶‹åŠ¿å¹…åº¦: {trend.get('trend_percentage', 0):.1f}%\")\n\n\nasync def demonstrate_system_health():\n    \"\"\"æ¼”ç¤ºç³»ç»Ÿå¥åº·çŠ¶æ€\"\"\"\n    \n    print(\"\\nğŸ¥ ç³»ç»Ÿå¥åº·çŠ¶æ€\")\n    print(\"=\" * 50)\n    \n    # æ¨¡æ‹Ÿç³»ç»Ÿå¥åº·æ£€æŸ¥APIè°ƒç”¨\n    dashboard = workflow_execution_engine.get_performance_dashboard()\n    \n    # æå–ç³»ç»Ÿå¥åº·æŒ‡æ ‡\n    system_stats = dashboard.get(\"statistics\", {}).get(\"system_statistics\", {})\n    alerts = dashboard.get(\"active_alerts\", {})\n    \n    # è®¡ç®—å¥åº·è¯„åˆ†\n    health_score = 100\n    \n    # CPUä½¿ç”¨ç‡å½±å“\n    cpu_usage = system_stats.get(\"average_cpu_usage\", 0)\n    if cpu_usage > 80:\n        health_score -= 20\n    elif cpu_usage > 60:\n        health_score -= 10\n    \n    # å†…å­˜ä½¿ç”¨ç‡å½±å“\n    memory_usage = system_stats.get(\"average_memory_usage\", 0)\n    if memory_usage > 85:\n        health_score -= 20\n    elif memory_usage > 70:\n        health_score -= 10\n    \n    # å‘Šè­¦å½±å“\n    critical_alerts = alerts.get(\"critical\", 0)\n    error_alerts = alerts.get(\"error\", 0)\n    warning_alerts = alerts.get(\"warning\", 0)\n    \n    health_score -= critical_alerts * 15\n    health_score -= error_alerts * 10\n    health_score -= warning_alerts * 5\n    \n    health_score = max(0, health_score)\n    \n    # ç¡®å®šå¥åº·çŠ¶æ€\n    if health_score >= 80:\n        status = \"healthy\"\n        status_icon = \"âœ…\"\n    elif health_score >= 60:\n        status = \"warning\"\n        status_icon = \"âš ï¸\"\n    elif health_score >= 40:\n        status = \"degraded\"\n        status_icon = \"ğŸ”¶\"\n    else:\n        status = \"critical\"\n        status_icon = \"ğŸ”´\"\n    \n    print(f\"ğŸ“Š ç³»ç»Ÿå¥åº·çŠ¶æ€: {status_icon} {status} ({health_score}åˆ†)\")\n    print(f\"ğŸ’» CPUä½¿ç”¨ç‡: {cpu_usage:.1f}%\")\n    print(f\"ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡: {memory_usage:.1f}%\")\n    print(f\"ğŸš¨ æ´»è·ƒå‘Šè­¦: {critical_alerts + error_alerts + warning_alerts}ä¸ª\")\n    \n    # ç”Ÿæˆå¥åº·å»ºè®®\n    recommendations = []\n    if cpu_usage > 80:\n        recommendations.append(\"ç³»ç»ŸCPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–æˆ–æ‰©å®¹èµ„æº\")\n    if memory_usage > 85:\n        recommendations.append(\"ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®æ¸…ç†ç¼“å­˜æˆ–å¢åŠ å†…å­˜\")\n    if critical_alerts > 0:\n        recommendations.append(\"å­˜åœ¨ä¸¥é‡å‘Šè­¦ï¼Œè¯·ç«‹å³æ£€æŸ¥å’Œè§£å†³\")\n    if error_alerts > 0:\n        recommendations.append(\"å­˜åœ¨é”™è¯¯å‘Šè­¦ï¼Œè¯·åŠæ—¶å¤„ç†\")\n    \n    if not recommendations:\n        recommendations.append(\"ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œè¯·ç»§ç»­ä¿æŒç›‘æ§\")\n    \n    print(f\"\\nğŸ’¡ å¥åº·å»ºè®®:\")\n    for rec in recommendations:\n        print(f\"   â€¢ {rec}\")\n\n\nasync def cleanup_and_summary():\n    \"\"\"æ¸…ç†å’Œæ€»ç»“\"\"\"\n    \n    print(\"\\nğŸ§¹ æ¸…ç†æ¼”ç¤ºæ•°æ®\")\n    print(\"=\" * 50)\n    \n    # è·å–æœ€ç»ˆç»Ÿè®¡\n    final_stats = workflow_execution_engine.get_execution_metrics()\n    \n    print(\"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:\")\n    if \"performance_monitoring\" in final_stats:\n        monitoring_stats = final_stats[\"performance_monitoring\"]\n        print(f\"   ç›‘æ§çŠ¶æ€: {'å¯ç”¨' if monitoring_stats.get('system_status', {}).get('monitoring_enabled') else 'ç¦ç”¨'}\")\n        print(f\"   æ”¶é›†æŒ‡æ ‡æ•°: {monitoring_stats.get('system_status', {}).get('metrics_count', 0)}\")\n        print(f\"   ç›‘æ§å·¥ä½œæµæ•°: {monitoring_stats.get('system_status', {}).get('workflow_count', 0)}\")\n        print(f\"   ç›‘æ§èŠ‚ç‚¹æ•°: {monitoring_stats.get('system_status', {}).get('node_count', 0)}\")\n    \n    # åœæ­¢æ€§èƒ½ç›‘æ§\n    await workflow_execution_engine.stop_performance_monitoring()\n    \n    # æ¸…ç†æ€§èƒ½å†å²æ•°æ®\n    workflow_execution_engine.clear_performance_history()\n    \n    print(\"âœ… æ€§èƒ½ç›‘æ§å·²åœæ­¢\")\n    print(\"âœ… å†å²æ•°æ®å·²æ¸…ç†\")\n\n\nasync def main():\n    \"\"\"ä¸»æ¼”ç¤ºå‡½æ•°\"\"\"\n    \n    print(\"ğŸ¯ å·¥ä½œæµæ€§èƒ½ç›‘æ§å®Œæ•´æ¼”ç¤º\")\n    print(\"=\" * 60)\n    \n    try:\n        # 1. è®¾ç½®æ€§èƒ½ç›‘æ§\n        await setup_performance_monitoring()\n        \n        # 2. è¿è¡Œç›‘æ§æ¼”ç¤º\n        execution_results = await run_monitoring_demo()\n        \n        # 3. åˆ†ææ€§èƒ½æ•°æ®\n        await analyze_performance_data()\n        \n        # 4. æ¼”ç¤ºå‘Šè­¦åŠŸèƒ½\n        await demonstrate_alerts()\n        \n        # 5. æ¼”ç¤ºè¯¦ç»†æŠ¥å‘Š\n        await demonstrate_detailed_reports()\n        \n        # 6. æ¼”ç¤ºç³»ç»Ÿå¥åº·çŠ¶æ€\n        await demonstrate_system_health()\n        \n        # 7. æ¸…ç†å’Œæ€»ç»“\n        await cleanup_and_summary()\n        \n        print(\"\\nğŸ‰ æ€§èƒ½ç›‘æ§æ¼”ç¤ºå®Œæˆ!\")\n        print(\"=\" * 60)\n        \n        # æ˜¾ç¤ºæ‰§è¡Œæ‘˜è¦\n        successful_executions = len([r for r in execution_results if r[\"status\"] == \"completed\"])\n        total_executions = len(execution_results)\n        \n        print(f\"ğŸ“Š æ‰§è¡Œæ‘˜è¦:\")\n        print(f\"   æ€»æ‰§è¡Œæ¬¡æ•°: {total_executions}\")\n        print(f\"   æˆåŠŸæ¬¡æ•°: {successful_executions}\")\n        print(f\"   æˆåŠŸç‡: {successful_executions/total_executions:.2%}\")\n        \n        if execution_results:\n            avg_duration = sum(r[\"duration\"] for r in execution_results) / len(execution_results)\n            print(f\"   å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_duration:.2f}ç§’\")\n        \n    except Exception as e:\n        print(f\"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n    \n    finally:\n        # ç¡®ä¿æ¸…ç†èµ„æº\n        try:\n            await workflow_execution_engine.stop_performance_monitoring()\n        except:\n            pass\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
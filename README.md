# RAG Platform (ragJ_platform)

An open-source, high-performance RAG (Retrieval-Augmented Generation) platform built with Python and Rust, designed for enterprise-level document-based AI assistants.

## ğŸš€ Project Overview

This project aims to create a powerful RAG platform, inspired by systems like Dify, but with a focus on performance by leveraging Rust for core data processing tasks. The platform uses a microservices architecture, combining Rust's performance for document handling with Python's flexibility for business logic and API services.

### Core Features

-   ğŸ§  **Intelligent Q&A**: Perform complex question-answering on your documents using a RAG pipeline.
-   ğŸ“š **Knowledge Base Management**: Easily create and manage distinct knowledge bases.
-   ğŸ“„ **Multi-Format Document Support**: Upload and process various document formats (starting with `.txt` and `.md`).
-   ğŸ”Œ **Flexible API**: A straightforward RESTful API for integration with any application.
-   ğŸ¤– **Multi-Model Support**: Supports DeepSeek, Qwen, and SiliconFlow APIs for different use cases.
-   âš¡ **High-Performance Backend**: FastAPI-based backend for asynchronous request handling.
-   ğŸ¨ **Modern Web Interface**: React-based frontend with Material-UI for intuitive management.
-   âš™ï¸ **Flexible Configuration**: Easy model switching and configuration management.
-   ğŸŒ **Internationalization**: Support for Chinese and English language switching.

## ğŸ—ï¸ System Architecture

## ğŸŒ Public API & Embedding

The platform exposes a simple public API (x-api-key) so you can validate workflows via chat and embed the assistant into any web page.

- Public endpoints (no login, require `x-api-key`):
  - `POST /api/v1/public/chat` â€” non-stream chat, request body is `ChatRequest`.
  - `POST /api/v1/public/chat/stream` â€” streaming chat (SSE), suitable for web embeds.
  - `POST /api/v1/public/workflows/{workflow_id}/execute` â€” run a saved workflow with input payload.

- Admin endpoints for API key management:
  - `POST /api/v1/admin/api-keys` â€” create a key (scopes: `chat`, `workflow`; optional `allowed_kb`, `allowed_workflow_id`).
  - `GET /api/v1/admin/api-keys` â€” list keys for your tenant.
  - `DELETE /api/v1/admin/api-keys/{id}` â€” revoke key.

### Embedding example

Option 1: iframe

```html
<iframe
  src="https://your-host/embed.html?api_key=YOUR_KEY&kb=your_kb&api_base=https://your-host"
  style="width: 100%; height: 560px; border: 1px solid #eee; border-radius: 8px"
></iframe>
```

Option 2: fetch from your own widget

```js
const res = await fetch('https://your-host/api/v1/public/chat/stream', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json', 'x-api-key': 'YOUR_KEY' },
  body: JSON.stringify({ message: 'Hello', knowledge_base_id: 'your_kb' }),
});
// Read SSE chunks from res.body and render progressively.
```

Notes:
- Public chat supports RAG with `knowledge_base_id` and will route to your tenantâ€™s KB automatically.
- Public workflow execution injects `tenant_id` and a system user for isolation and auditing.

The system is designed with a clean separation of concerns:

-   **FastAPI Backend (Python)**: Handles all API requests, business logic, and orchestration.
-   **React Frontend (TypeScript)**: Modern web interface with Material-UI components.
-   **Milvus**: Acts as the vector database for storing and retrieving document embeddings.
-   **Elasticsearch**: Provides full-text search capabilities for hybrid retrieval.
-   **Multi-Model Support**: Integrates with DeepSeek, Qwen, and SiliconFlow APIs.

## ğŸ“¦ Quick Start

This guide will help you get the Python backend up and running from the source code.

### Prerequisites

-   Python 3.9+
-   An available Milvus instance.
-   A Dashscope API Key for the Qwen models.

### Local Setup

1.  **Clone the Repository**
    ```bash
    git clone <your-repo-url>
    cd ragJ_platform/backend
    ```

2.  **Configure Environment Variables**
    Create a `.env` file in the `backend/` directory by copying the example:
    ```bash
    cp .env.example .env
    ```
    Now, edit the `.env` file and set your credentials:
    ```
    # backend/.env

    # Your Dashscope API Key for Qwen models
    DASHSCOPE_API_KEY="your_sk_key_here"

    # Connection details for your Milvus instance
    MILVUS_HOST="localhost"
    MILVUS_PORT="19530"
    ```

3.  **Install Dependencies**
    It is highly recommended to use a virtual environment.
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install --upgrade pip
    pip install -r requirements.txt
    ```

4.  **Run the Server**
    ```bash
    uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
    ```

5.  **Access the API**
    Once the server is running, you can access the interactive API documentation at:
    [http://localhost:8000/docs](http://localhost:8000/docs)

### Frontend Setup

The platform includes a modern React-based web interface for easy management.

1.  **Navigate to Frontend Directory**
    ```bash
    cd frontend
    ```

2.  **Install Dependencies**
    ```bash
    npm install
    ```

3.  **Start Development Server**
    ```bash
    npm run dev
    ```

4.  **Access Web Interface**
    The frontend will be available at:
    [http://localhost:5173](http://localhost:5173)

### Web Interface Features

-   ğŸ“Š **Dashboard**: System overview and statistics
-   ğŸ“š **Knowledge Base Management**: Create, delete, and manage knowledge bases
-   ğŸ’¬ **Intelligent Chat**: Interactive chat interface with knowledge base selection
-   âš™ï¸ **Model Configuration**: Easy setup for DeepSeek, Qwen, and SiliconFlow APIs
-   ğŸ“ **Document Management**: Upload and manage documents (coming soon)
-   ğŸŒ **Language Support**: Switch between Chinese and English interface

## ğŸ”§ API Usage Guide

Here is how to use the core RAG pipeline via the API.

### Step 1: Create a Knowledge Base

First, create a new knowledge base. This corresponds to a new "collection" in Milvus.

```bash
curl -X 'POST' \
  'http://localhost:8000/api/v1/knowledge-bases/' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "name": "my_first_kb",
    "description": "A knowledge base for testing."
  }'
```

A successful response will confirm that the knowledge base was created.

### Step 2: Upload a Document

Next, upload a document (`.txt` or `.md`) to your new knowledge base. The system will process it in the background (chunking, embedding, and indexing).

**Note:** Make sure you have a file named `sample.txt` in your current directory.

```bash
curl -X 'POST' \
  'http://localhost:8000/api/v1/knowledge-bases/my_first_kb/documents/' \
  -H 'accept: application/json' \
  -F 'file=@sample.txt;type=text/plain'
```

The API will respond immediately, confirming that the file has been accepted for processing.

### Step 3: Chat with Your Knowledge Base

Once the document has been processed, you can start asking questions. The system will retrieve relevant context from your documents to generate an answer.

```bash
curl -X 'POST' \
  'http://localhost:8000/api/v1/chat/' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
    "message": "What is this document about?",
    "knowledge_base_id": "my_first_kb",
    "model": "qwen-turbo"
  }'
```

The response will contain the AI's answer, generated based on the content of the document you uploaded.

## ğŸ¤– Model Configuration

The platform supports multiple AI model providers for different use cases:

### Supported Providers

#### DeepSeek
- **Best for**: Code generation, technical documentation
- **Models**: `deepseek-chat`, `deepseek-coder`
- **API**: https://api.deepseek.com/v1

#### Qwen (é€šä¹‰åƒé—®)
- **Best for**: Chinese language tasks, comprehensive AI capabilities
- **Models**: `qwen-turbo`, `qwen-plus`, `qwen-max`
- **API**: https://dashscope.aliyuncs.com/compatible-mode/v1

#### SiliconFlow (ç¡…åŸºæµåŠ¨)
- **Best for**: Cost-effective embedding and reranking
- **Models**: Various open-source models including BGE series
- **API**: https://api.siliconflow.cn/v1

### Configuration Presets

The web interface provides three pre-configured setups:

1. **Economic Configuration** (ç»æµé…ç½®)
   - Chat: DeepSeek
   - Embedding: SiliconFlow BGE
   - Rerank: SiliconFlow BGE

2. **Premium Configuration** (é«˜è´¨é‡é…ç½®)
   - Chat: Qwen Max
   - Embedding: Qwen Embedding
   - Rerank: Qwen Rerank

3. **Chinese Optimized** (ä¸­æ–‡ä¼˜åŒ–)
   - Chat: Qwen Plus
   - Embedding: SiliconFlow BGE Chinese
   - Rerank: SiliconFlow BGE Reranker

### API Key Setup

To configure your models:

1. Visit the **Settings** page in the web interface
2. Choose a preset or configure manually
3. Add your API keys for each provider
4. Test the connections
5. Save the configuration

### Language Support

The web interface supports both Chinese and English:

- **Language Switching**: Click the language switcher in the sidebar to change between Chinese (ä¸­æ–‡) and English
- **Auto Detection**: The system automatically detects your browser language preference
- **Persistent Settings**: Your language preference is saved locally and remembered across sessions

#### Supported Languages

- **Chinese (ä¸­æ–‡)**: Full interface translation for Chinese users
- **English**: Complete English interface for international users

All interface elements, including:
- Navigation menus
- Form labels and buttons
- Error messages and notifications
- Help text and descriptions
- Model configuration options

Are fully translated and localized for both languages.

## ğŸ“š åŠŸèƒ½æ¨¡å—

### 1. æ–‡æ¡£å¤„ç†
- **æ”¯æŒæ ¼å¼**: PDFã€DOCXã€TXTã€Markdownã€HTML
- **å¤„ç†èƒ½åŠ›**: æ–‡æœ¬æå–ã€ç»“æ„åŒ–åˆ†æã€å…ƒæ•°æ®æå–
- **åˆ†å—ç­–ç•¥**: æ™ºèƒ½åˆ†å—ã€å›ºå®šé•¿åº¦ã€è¯­ä¹‰åˆ†å‰²

### 2. å‘é‡åŒ–æœåŠ¡
- **åµŒå…¥æ¨¡å‹**: OpenAIã€Hugging Faceã€æœ¬åœ°æ¨¡å‹
- **å‘é‡å­˜å‚¨**: é«˜æ•ˆç´¢å¼•å’Œæ£€ç´¢ä¼˜åŒ–
- **ç›¸ä¼¼æ€§æœç´¢**: æ··åˆæœç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰

### 3. é—®ç­”ç³»ç»Ÿ
- **RAGæµç¨‹**: æ£€ç´¢+ç”Ÿæˆçš„å®Œæ•´æµç¨‹
- **æ¨¡å‹æ”¯æŒ**: GPT-4ã€Claudeã€å¼€æºLLM
- **ä¸Šä¸‹æ–‡ç®¡ç†**: å¤šè½®å¯¹è¯æ”¯æŒ

### 3. LangGraphæ™ºèƒ½ä½“ç³»ç»Ÿ
- **å·¥ä½œæµæ„å»º**: åŸºäºå›¾çš„æ™ºèƒ½ä½“å·¥ä½œæµè®¾è®¡
- **çŠ¶æ€ç®¡ç†**: æŒä¹…åŒ–çš„å¯¹è¯å’Œä»»åŠ¡çŠ¶æ€
- **å¤šæ™ºèƒ½ä½“åä½œ**: æ”¯æŒæ™ºèƒ½ä½“é—´çš„åä½œå’Œé€šä¿¡
- **æ¡ä»¶è·¯ç”±**: åŸºäºæ¡ä»¶çš„æ™ºèƒ½å·¥ä½œæµè·¯ç”±

### 4. çŸ¥è¯†åº“ç®¡ç†
- **ç»„ç»‡ç»“æ„**: å±‚çº§åŒ–çŸ¥è¯†åº“ç®¡ç†
- **æƒé™æ§åˆ¶**: ç»†ç²’åº¦è®¿é—®æƒé™
- **ç‰ˆæœ¬æ§åˆ¶**: æ–‡æ¡£ç‰ˆæœ¬ç®¡ç†

## ğŸ”’ å®‰å…¨é…ç½®

### APIè®¤è¯
```python
# ç”ŸæˆAPIå¯†é’¥
from backend.app.core.security import generate_api_key

api_key = generate_api_key(user_id="user_123")
```

### æƒé™é…ç½®
```yaml
# config/permissions.yml
roles:
  admin:
    - knowledge_base:*
    - document:*
    - user:*
  user:
    - knowledge_base:read
    - document:upload
    - chat:query
```

## ğŸš€ éƒ¨ç½²é…ç½®

### ç”Ÿäº§ç¯å¢ƒå˜é‡

```bash
# .env.production
DATABASE_URL=postgresql://user:pass@db:5432/ragj_platform
REDIS_URL=redis://redis:6379/0
QDRANT_URL=http://qdrant:6333
MINIO_ENDPOINT=minio:9000

# LLMé…ç½®
OPENAI_API_KEY=your_openai_key
OPENAI_BASE_URL=https://api.openai.com/v1

# å®‰å…¨é…ç½®
SECRET_KEY=your_super_secret_key
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# æœåŠ¡é…ç½®
API_V1_STR=/api/v1
PROJECT_NAME=RAG Platform
DEBUG=false
```

### ç›‘æ§é…ç½®

```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
  
  grafana:
    image: grafana/grafana
    ports:
      - "3001:3000"
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### RustæœåŠ¡ä¼˜åŒ–
- å¹¶å‘æ–‡æ¡£å¤„ç†
- å†…å­˜æ˜ å°„æ–‡ä»¶è¯»å–
- SIMDå‘é‡è®¡ç®—ä¼˜åŒ–

### æ•°æ®åº“ä¼˜åŒ–
```sql
-- å‘é‡æ£€ç´¢ç´¢å¼•
CREATE INDEX idx_embeddings_vector ON document_chunks 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);

-- å…ƒæ•°æ®æŸ¥è¯¢ç´¢å¼•
CREATE INDEX idx_documents_kb_id ON documents(knowledge_base_id);
CREATE INDEX idx_chunks_doc_id ON document_chunks(document_id);
```

### ç¼“å­˜ç­–ç•¥
- Redisç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢
- åµŒå…¥å‘é‡ç¼“å­˜
- æ–‡æ¡£å¤„ç†ç»“æœç¼“å­˜

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# ä»£ç æ ¼å¼åŒ–
black backend/
rustfmt rust_services/src/**/*.rs

# ç±»å‹æ£€æŸ¥
mypy backend/app/

# æµ‹è¯•
pytest backend/tests/
cargo test --manifest-path rust_services/Cargo.toml
```

### APIæ–‡æ¡£ç”Ÿæˆ

```bash
# å¯åŠ¨æœåŠ¡åè®¿é—®
http://localhost:8000/docs        # Swagger UI
http://localhost:8000/redoc       # ReDoc
http://localhost:8000/openapi.json # OpenAPIè§„èŒƒ
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. åˆ›å»ºPull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ†˜ æ”¯æŒä¸å¸®åŠ©

- ğŸ“§ é‚®ç®±: support@ragj-platform.com
- ğŸ’¬ ç¤¾åŒºè®¨è®º: [GitHub Discussions](https://github.com/your-org/ragJ_platform/discussions)
- ğŸ› é—®é¢˜åé¦ˆ: [GitHub Issues](https://github.com/your-org/ragJ_platform/issues)
- ğŸ“– å®Œæ•´æ–‡æ¡£: [Documentation](https://docs.ragj-platform.com)

## ğŸ—ºï¸ å¼€å‘è·¯çº¿å›¾

- [x] åŸºç¡€RAGåŠŸèƒ½å®ç°
- [x] Rusté«˜æ€§èƒ½æ–‡æ¡£å¤„ç†
- [x] APIæ¥å£è®¾è®¡
- [ ] Webç®¡ç†ç•Œé¢
- [ ] å¤šç§Ÿæˆ·æ”¯æŒ
- [ ] ä¼ä¸šçº§æƒé™ç®¡ç†
- [ ] æ€§èƒ½ç›‘æ§ä¸å‘Šè­¦
- [ ] æ’ä»¶ç³»ç»Ÿ
- [ ] å¤šè¯­è¨€æ”¯æŒ

---

**æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªåŸºç¡€ç‰ˆæœ¬çš„å®ç°ï¼Œé€‚ç”¨äºå­¦ä¹ å’Œå°è§„æ¨¡éƒ¨ç½²ã€‚ç”Ÿäº§ç¯å¢ƒä½¿ç”¨è¯·æ ¹æ®å®é™…éœ€æ±‚è¿›è¡Œå®‰å…¨åŠ å›ºå’Œæ€§èƒ½ä¼˜åŒ–ã€‚
